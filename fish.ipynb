{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6XZgofXzwuF",
        "outputId": "6386e282-5b90-4127-ff79-514f69df6e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14238, done.\u001b[K\n",
            "remote: Counting objects: 100% (178/178), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 14238 (delta 110), reused 125 (delta 78), pack-reused 14060\u001b[K\n",
            "Receiving objects: 100% (14238/14238), 13.62 MiB | 20.16 MiB/s, done.\n",
            "Resolving deltas: 100% (9766/9766), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT5p6YI21C_F",
        "outputId": "f00bedc1-036f-4d20-be0d-04072d659cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (7.9.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (7.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (5.4.8)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.7.3)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.13.1+cu113)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 27)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (0.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.38.4)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.3.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.50.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 22)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.2.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 6)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 6)) (0.7.0)\n",
            "Installing collected packages: smmap, jedi, gitdb, thop, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.29 jedi-0.18.2 smmap-5.0.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vLPI_vpd0VpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --img 416 --data /content/drive/MyDrive/fish/fish_project/datafile.yaml  --cfg /content/yolov5/models/yolov5l.yaml --weights /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt --epochs 10 --batch 35 --cache --evolve 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X4brcSW1S1r",
        "outputId": "69688c14-75b9-43ae-a6de-9da99f3d47ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt, cfg=/content/yolov5/models/yolov5l.yaml, data=/content/drive/MyDrive/fish/fish_project/datafile.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=35, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=50, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-10-g10c025d Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 6.19MB/s]\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 216.45it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:00<00:00, 1571.04it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.43G     0.1167    0.01636   0.005332         49        416: 100% 6/6 [00:04<00:00,  1.29it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.43G     0.1081    0.01565   0.006152         36        416: 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.43G     0.1036    0.01652   0.005101         39        416: 100% 6/6 [00:03<00:00,  1.81it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.43G    0.09742    0.01759   0.005787         41        416: 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.43G    0.08839    0.01939     0.0043         45        416: 100% 6/6 [00:03<00:00,  1.80it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.43G    0.07787    0.02161   0.005466         38        416: 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.43G     0.0706    0.02429   0.004853         34        416: 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.43G     0.0676     0.0244   0.004533         43        416: 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.43G     0.0639     0.0249   0.005402         40        416: 100% 6/6 [00:03<00:00,  1.77it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.43G    0.06428    0.02357   0.004008         41        416: 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.75it/s]\n",
            "                   all         23         23      0.904      0.818      0.922      0.461\n",
            "\n",
            "10 epochs completed in 0.010 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m1 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.90421,                0.818,              0.92188,              0.46063,             0.081253,             0.011617,            0.0064172,                 0.01,                 0.01,                0.937,               0.0005,                    3,                  0.8,                  0.1,                 0.05,                  0.5,                    1,                    1,                    1,                  0.2,                    4,                    0,                0.015,                  0.7,                  0.4,                    0,                  0.1,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.00055, warmup_epochs=3.0, warmup_momentum=0.82167, warmup_bias_lr=0.10564, box=0.04395, cls=0.51046, cls_pw=1.0, obj=1.2685, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.72077, hsv_v=0.4, degrees=0.0, translate=0.06826, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.9354, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0006015625), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.63it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:00<00:00, 1004.55it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 5.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.586-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.49G    0.08857    0.03873     0.0264         32        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.49G      0.071    0.04514    0.02383         44        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.49G     0.0588    0.04662    0.02008         36        416: 100% 6/6 [00:03<00:00,  1.74it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.49G    0.05239    0.05018    0.01696         42        416: 100% 6/6 [00:03<00:00,  1.73it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.49G    0.04936    0.05051    0.01361         46        416: 100% 6/6 [00:03<00:00,  1.72it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.49G      0.047    0.04679    0.01131         34        416: 100% 6/6 [00:03<00:00,  1.71it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.49G     0.0476    0.04669   0.009547         35        416: 100% 6/6 [00:03<00:00,  1.71it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.49G    0.04402    0.04393   0.008113         31        416: 100% 6/6 [00:03<00:00,  1.71it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.49G    0.04221    0.04491   0.007687         42        416: 100% 6/6 [00:03<00:00,  1.69it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.49G    0.04038    0.04381   0.008406         38        416: 100% 6/6 [00:03<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.57it/s]\n",
            "                   all         23         23      0.861      0.441      0.702      0.353\n",
            "\n",
            "10 epochs completed in 0.010 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m2 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.86125,              0.44118,               0.7016,              0.35285,             0.054908,             0.021013,             0.016235,                 0.01,                 0.01,                0.937,              0.00055,                    3,              0.82167,              0.10564,              0.04395,              0.51046,                    1,               1.2685,                    1,                  0.2,                    4,                    0,                0.015,              0.72077,                  0.4,                    0,              0.06826,                  0.5,                    0,                    0,                    0,                  0.5,               0.9354,                    0,                    0,                    2\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00994, lrf=0.01007, momentum=0.93674, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.7966, warmup_bias_lr=0.10106, box=0.04899, cls=0.49441, cls_pw=0.99213, obj=1.001, obj_pw=1.0, iou_t=0.2, anchor_t=4.02109, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.70869, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.49971, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.03547\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.03547\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00994) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 220.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 993.57it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1144    0.01637   0.005272         49        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G      0.106    0.01571   0.006117         36        416: 100% 6/6 [00:03<00:00,  1.66it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1017    0.01652    0.00505         39        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09579    0.01753   0.005715         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08754    0.01916   0.004264         45        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07711    0.02145   0.005375         38        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.06977    0.02418    0.00477         34        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06661    0.02441   0.004456         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06293    0.02493    0.00537         40        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06321    0.02375    0.00398         41        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.75it/s]\n",
            "                   all         23         23       0.79      0.745      0.834       0.39\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m3 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.78956,               0.7451,              0.83355,              0.39043,             0.080528,             0.011422,             0.005929,              0.00994,              0.01007,              0.93674,               0.0005,                    3,               0.7966,              0.10106,              0.04899,              0.49441,              0.99213,                1.001,                    1,                  0.2,               4.0211,                    0,                0.015,              0.70869,                  0.4,                    0,                  0.1,              0.49971,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.0355\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01045, lrf=0.01082, momentum=0.911, weight_decay=0.00049, warmup_epochs=3.15358, warmup_momentum=0.84242, warmup_bias_lr=0.09247, box=0.05328, cls=0.48049, cls_pw=1.00626, obj=1.06144, obj_pw=0.88487, iou_t=0.2, anchor_t=4.45604, fl_gamma=0.0, hsv_h=0.01443, hsv_s=0.75051, hsv_v=0.4, degrees=0.0, translate=0.10384, scale=0.49413, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.73958\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.73958\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01045) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 220.63it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 833.87it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 8.98 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1245    0.01669   0.005197         49        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1155    0.01606   0.005976         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1094    0.01702   0.004965         38        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.1016    0.01839   0.005567         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08818    0.02144    0.00429         45        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07748    0.02341   0.005598         38        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07346    0.02515   0.004905         34        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.07098    0.02545   0.004552         43        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06768    0.02549   0.005251         40        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06873    0.02408   0.003887         41        416: 100% 6/6 [00:04<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.43it/s]\n",
            "                   all         23         23      0.837      0.795       0.89      0.388\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m4 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.83674,              0.79472,              0.89009,              0.38778,             0.082463,             0.012528,            0.0085137,              0.01045,              0.01082,                0.911,              0.00049,               3.1536,              0.84242,              0.09247,              0.05328,              0.48049,               1.0063,               1.0614,              0.88487,                  0.2,                4.456,                    0,              0.01443,              0.75051,                  0.4,                    0,              0.10384,              0.49413,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.7396\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00933, lrf=0.01313, momentum=0.92781, weight_decay=0.00046, warmup_epochs=2.04276, warmup_momentum=0.85728, warmup_bias_lr=0.11354, box=0.04464, cls=0.43789, cls_pw=0.70055, obj=0.98124, obj_pw=0.9276, iou_t=0.2, anchor_t=3.78859, fl_gamma=0.0, hsv_h=0.01645, hsv_s=0.54837, hsv_v=0.33657, degrees=0.0, translate=0.11533, scale=0.59919, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.78379, mixup=0.0, copy_paste=0.0, anchors=3.6316\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.6316\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     50260  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46156244 parameters, 46156244 gradients, 108.3 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00933) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000503125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 217.00it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9201: 100% 1000/1000 [00:01<00:00, 762.03it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 1.0000 best possible recall, 11.87 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=416, metric_all=0.584/0.920-mean/best, past_thr=0.588-mean: 122,373, 374,131, 146,337, 281,211, 363,186, 187,400, 395,202, 252,338, 231,380, 364,251, 411,246, 311,414\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.42G    0.08889    0.02509    0.01827         31        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.43G    0.07828    0.02663    0.01732         41        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.43G    0.06549    0.03077    0.01621         39        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.43G    0.05721    0.03292      0.015         36        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.43G    0.05187    0.03308    0.01346         35        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.43G    0.04858    0.03286    0.01222         29        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.43G    0.04814    0.03392    0.01108         31        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.43G    0.04582    0.03409    0.01017         30        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.43G    0.04502    0.03375   0.009684         45        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.43G    0.04334    0.03316   0.008593         35        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.23it/s]\n",
            "                   all         23         23      0.687      0.471      0.467      0.203\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m5 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.68666,              0.47059,              0.46699,              0.20297,             0.057115,             0.016754,             0.012933,              0.00933,              0.01313,              0.92781,              0.00046,               2.0428,              0.85728,              0.11354,              0.04464,              0.43789,              0.70055,              0.98124,               0.9276,                  0.2,               3.7886,                    0,              0.01645,              0.54837,              0.33657,                    0,              0.11533,              0.59919,                    0,                    0,                    0,                  0.5,              0.78379,                    0,                    0,               3.6316\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01007, lrf=0.01, momentum=0.93731, weight_decay=0.0005, warmup_epochs=2.98355, warmup_momentum=0.80254, warmup_bias_lr=0.09958, box=0.05016, cls=0.49882, cls_pw=0.98855, obj=1.00975, obj_pw=1.00236, iou_t=0.2, anchor_t=4.03526, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.69619, hsv_v=0.39989, degrees=0.0, translate=0.09979, scale=0.50061, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01007) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 218.56it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 902.23it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G      0.117    0.01653   0.005282         49        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1084     0.0159   0.006167         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1039    0.01678   0.005077         39        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09754    0.01786   0.005742         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08817    0.01986   0.004262         45        416: 100% 6/6 [00:04<00:00,  1.46it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07785    0.02202   0.005481         38        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.07072    0.02474   0.004834         34        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06768    0.02486   0.004482         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06412    0.02527   0.005395         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06451    0.02401   0.004003         40        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.88it/s]\n",
            "                   all         23         23      0.901      0.812      0.922      0.444\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m6 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.90097,              0.81212,              0.92188,              0.44397,             0.081138,             0.011787,            0.0064466,              0.01007,                 0.01,              0.93731,               0.0005,               2.9836,              0.80254,              0.09958,              0.05016,              0.49882,              0.98855,               1.0097,               1.0024,                  0.2,               4.0353,                    0,                0.015,              0.69619,              0.39989,                    0,              0.09979,              0.50061,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    3\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01, momentum=0.94605, weight_decay=0.00049, warmup_epochs=3.03283, warmup_momentum=0.81718, warmup_bias_lr=0.1, box=0.05, cls=0.49134, cls_pw=1.0175, obj=1.0041, obj_pw=1.0, iou_t=0.2, anchor_t=4.08167, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.71879, hsv_v=0.40863, degrees=0.0, translate=0.1, scale=0.49412, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.80183\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.80183\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 211.60it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 876.61it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1166    0.01652   0.005297         49        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1081    0.01594   0.006209         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1034    0.01679   0.005108         39        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09699    0.01787   0.005748         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08698    0.02014   0.004238         45        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07686    0.02223   0.005516         38        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G       0.07    0.02483    0.00488         34        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06729    0.02496   0.004484         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06368    0.02534   0.005346         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06432    0.02415   0.003989         41        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.97it/s]\n",
            "                   all         23         23      0.824      0.887      0.929      0.462\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m7 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.82379,              0.88725,              0.92874,              0.46205,              0.08106,             0.011566,            0.0061875,              0.00991,                 0.01,              0.94605,              0.00049,               3.0328,              0.81718,                  0.1,                 0.05,              0.49134,               1.0175,               1.0041,                    1,                  0.2,               4.0817,                    0,              0.01495,              0.71879,              0.40863,                    0,                  0.1,              0.49412,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.8018\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01, momentum=0.94495, weight_decay=0.00049, warmup_epochs=3.02422, warmup_momentum=0.81812, warmup_bias_lr=0.10022, box=0.04996, cls=0.4916, cls_pw=1.01626, obj=1.00286, obj_pw=1.0, iou_t=0.2, anchor_t=4.08052, fl_gamma=0.0, hsv_h=0.0149, hsv_s=0.71987, hsv_v=0.40666, degrees=0.0, translate=0.10043, scale=0.49207, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.78454\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.78454\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 221.10it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 852.72it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1165    0.01649   0.005285         49        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1079    0.01592   0.006207         36        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1033    0.01679    0.00512         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09684    0.01784   0.005715         41        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08683    0.02012    0.00424         45        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07672    0.02218   0.005499         38        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.07002     0.0248   0.004884         34        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06722    0.02496   0.004482         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06361    0.02531   0.005333         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06424    0.02418   0.003949         41        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.67it/s]\n",
            "                   all         23         23       0.88      0.778      0.898      0.452\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m8 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.88017,              0.77834,              0.89793,               0.4516,              0.08119,              0.01167,            0.0064899,              0.00991,                 0.01,              0.94495,              0.00049,               3.0242,              0.81812,              0.10022,              0.04996,               0.4916,               1.0163,               1.0029,                    1,                  0.2,               4.0805,                    0,               0.0149,              0.71987,              0.40666,                    0,              0.10043,              0.49207,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.7845\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01011, lrf=0.01001, momentum=0.93874, weight_decay=0.0005, warmup_epochs=3.00278, warmup_momentum=0.79621, warmup_bias_lr=0.10084, box=0.05, cls=0.49739, cls_pw=1.00238, obj=0.99427, obj_pw=1.00565, iou_t=0.2, anchor_t=4.00052, fl_gamma=0.0, hsv_h=0.01512, hsv_s=0.69465, hsv_v=0.4, degrees=0.0, translate=0.09956, scale=0.49627, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.99594, mixup=0.0, copy_paste=0.0, anchors=2.97158\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.97158\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01011) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.52it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 782.49it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G      0.117    0.01602   0.005584         49        416: 100% 6/6 [00:04<00:00,  1.38it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1076    0.01549   0.005987         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1033    0.01653   0.005135         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09744    0.01751   0.005348         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08965    0.01939   0.004991         34        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07849    0.02183   0.005398         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.07087    0.02473   0.005043         34        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06789    0.02432   0.004471         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06438    0.02413   0.005402         37        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06459    0.02349   0.004694         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.67it/s]\n",
            "                   all         23         23      0.824      0.838      0.924       0.36\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m9 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.82413,              0.83799,              0.92361,              0.35958,             0.081694,             0.011289,            0.0055588,              0.01011,              0.01001,              0.93874,               0.0005,               3.0028,              0.79621,              0.10084,                 0.05,              0.49739,               1.0024,              0.99427,               1.0056,                  0.2,               4.0005,                    0,              0.01512,              0.69465,                  0.4,                    0,              0.09956,              0.49627,                    0,                    0,                    0,                  0.5,              0.99594,                    0,                    0,               2.9716\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01211, lrf=0.01, momentum=0.937, weight_decay=0.00062, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.09385, box=0.03078, cls=0.5, cls_pw=0.92505, obj=1.00726, obj_pw=0.86136, iou_t=0.2, anchor_t=4.4714, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.80741, hsv_v=0.40133, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.04161\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.04161\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01211) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000678125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 223.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 814.78it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 5.99 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.583-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G    0.06429    0.02874    0.02444         49        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G    0.05395    0.03062    0.02236         36        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G    0.04403    0.03622    0.01905         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.03721     0.0387     0.0162         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.03547    0.03907    0.01303         45        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G     0.0342    0.03656    0.01168         38        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.03462    0.03571   0.009557         34        416: 100% 6/6 [00:04<00:00,  1.44it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.03306    0.03426   0.008238         43        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.03164    0.03432   0.007909         40        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.03102    0.03226   0.006604         41        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.56it/s]\n",
            "                   all         23         23      0.894      0.438      0.735      0.322\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m10 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.89401,              0.43753,              0.73476,              0.32206,             0.040632,             0.015546,             0.013658,              0.01211,                 0.01,                0.937,              0.00062,                    3,                  0.8,              0.09385,              0.03078,                  0.5,              0.92505,               1.0073,              0.86136,                  0.2,               4.4714,                    0,                0.015,              0.80741,              0.40133,                    0,                  0.1,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.0416\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01023, lrf=0.01132, momentum=0.83725, weight_decay=0.00056, warmup_epochs=3.62417, warmup_momentum=0.61408, warmup_bias_lr=0.13189, box=0.03818, cls=0.49477, cls_pw=1.03127, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.01781, hsv_s=0.67953, hsv_v=0.33074, degrees=0.0, translate=0.10502, scale=0.44664, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.56285\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.56285\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01023) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0006125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.63it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 880.43it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G    0.08937    0.01623   0.005364         49        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G    0.08343    0.01554   0.006253         34        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G    0.08117    0.01615   0.005227         38        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.07904    0.01629   0.005926         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.07483    0.01666     0.0044         43        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07258     0.0169   0.005751         38        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.06957    0.01869   0.004842         35        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06479    0.01987   0.004344         42        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.05919     0.0214   0.005175         40        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.05764    0.02104   0.004119         41        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.65it/s]\n",
            "                   all         23         23      0.757      0.662      0.735      0.277\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m11 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.75727,              0.66176,              0.73485,              0.27663,             0.064232,              0.01246,             0.009096,              0.01023,              0.01132,              0.83725,              0.00056,               3.6242,              0.61408,              0.13189,              0.03818,              0.49477,               1.0313,                    1,                    1,                  0.2,                    4,                    0,              0.01781,              0.67953,              0.33074,                    0,              0.10502,              0.44664,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.5629\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.90636, weight_decay=0.00054, warmup_epochs=2.86264, warmup_momentum=0.94487, warmup_bias_lr=0.09234, box=0.04729, cls=0.5, cls_pw=1.0466, obj=1.0, obj_pw=0.94079, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0153, hsv_s=0.73006, hsv_v=0.36091, degrees=0.0, translate=0.10772, scale=0.51479, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.89971, mixup=0.0, copy_paste=0.0, anchors=2.21227\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.21227\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000590625), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 221.44it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 948.54it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 5.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.586-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.0937    0.02918    0.02653         34        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G    0.07529      0.031    0.02331         38        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.06202    0.03636    0.01802         35        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.05462    0.03897    0.01347         41        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.05232    0.03743    0.01012         38        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.04977    0.03754   0.008727         42        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.04791    0.03352   0.008194         32        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.04651    0.03287   0.006318         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.04378     0.0327   0.005214         34        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.04357     0.0333   0.005806         34        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.56it/s]\n",
            "                   all         23         23      0.875      0.412      0.905      0.344\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m12 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.87539,              0.41176,              0.90532,              0.34386,              0.05741,             0.017068,             0.019412,                 0.01,                 0.01,              0.90636,              0.00054,               2.8626,              0.94487,              0.09234,              0.04729,                  0.5,               1.0466,                    1,              0.94079,                  0.2,                    4,                    0,               0.0153,              0.73006,              0.36091,                    0,              0.10772,              0.51479,                    0,                    0,                    0,                  0.5,              0.89971,                    0,                    0,               2.2123\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01048, momentum=0.88144, weight_decay=0.00036, warmup_epochs=1.50912, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.04502, cls=0.7103, cls_pw=1.0, obj=1.37246, obj_pw=1.26629, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.01341, hsv_s=0.64445, hsv_v=0.32769, degrees=0.0, translate=0.09498, scale=0.64031, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.89085, mixup=0.0, copy_paste=0.0, anchors=4.19975\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=4.19975\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     50260  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46156244 parameters, 46156244 gradients, 108.3 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.00039375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.77it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9201: 100% 1000/1000 [00:01<00:00, 952.83it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 11.91 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=416, metric_all=0.584/0.920-mean/best, past_thr=0.587-mean: 122,373, 374,131, 146,337, 281,211, 363,186, 187,400, 395,202, 252,338, 231,380, 364,251, 411,246, 311,414\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.43G    0.09128    0.04552    0.03684         40        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.43G    0.08092    0.04858    0.03432         40        416: 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.43G    0.06978    0.05535    0.03054         34        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.43G    0.05998    0.06501    0.02713         48        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.43G    0.05414    0.06489    0.02303         37        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.43G    0.05154     0.0631    0.01993         39        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.43G    0.05009    0.05887    0.01749         34        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.43G    0.04888    0.05611    0.01456         38        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.43G    0.04841    0.05504    0.01293         36        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.43G    0.04766     0.0531    0.01208         38        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.47it/s]\n",
            "                   all         23         23       0.59      0.176       0.11     0.0439\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m13 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.58985,              0.17647,              0.11028,             0.043916,             0.062587,             0.031702,             0.028899,                 0.01,              0.01048,              0.88144,              0.00036,               1.5091,                  0.8,                  0.1,              0.04502,               0.7103,                    1,               1.3725,               1.2663,                  0.2,                    4,                    0,              0.01341,              0.64445,              0.32769,                    0,              0.09498,              0.64031,                    0,                    0,                    0,                  0.5,              0.89085,                    0,                    0,               4.1997\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01252, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.04171, warmup_momentum=0.8, warmup_bias_lr=0.11389, box=0.04382, cls=0.54086, cls_pw=0.77398, obj=1.0, obj_pw=1.16661, iou_t=0.2, anchor_t=4.80251, fl_gamma=0.0, hsv_h=0.01352, hsv_s=0.80049, hsv_v=0.38997, degrees=0.0, translate=0.08329, scale=0.42122, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.43658\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.43658\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01252) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 840.89it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.21: 1.0000 best possible recall, 9.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.587-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1026    0.01864   0.005213         49        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G    0.09504    0.01874   0.006155         35        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G    0.09054    0.02008   0.004885         40        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.08466    0.02103   0.005496         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.07509    0.02429   0.004142         41        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.06669     0.0265   0.005471         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.06228    0.02923   0.004762         35        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06008    0.02956    0.00439         41        416: 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.05662    0.02933   0.005223         39        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.05719    0.02832   0.003823         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.58it/s]\n",
            "                   all         23         23      0.856      0.828      0.867      0.382\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m14 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.85555,              0.82843,              0.86688,              0.38198,               0.0705,             0.013289,            0.0056456,              0.01252,                 0.01,                0.937,               0.0005,               3.0417,                  0.8,              0.11389,              0.04382,              0.54086,              0.77398,                    1,               1.1666,                  0.2,               4.8025,                    0,              0.01352,              0.80049,              0.38997,                    0,              0.08329,              0.42122,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.4366\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.00049, warmup_epochs=3.03224, warmup_momentum=0.7628, warmup_bias_lr=0.09664, box=0.05, cls=0.51469, cls_pw=0.93932, obj=1.0, obj_pw=1.0212, iou_t=0.2, anchor_t=3.88922, fl_gamma=0.0, hsv_h=0.01418, hsv_s=0.75072, hsv_v=0.38163, degrees=0.0, translate=0.1056, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.13274\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.13274\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 221.03it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 804.48it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 1.0000 best possible recall, 8.93 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1168    0.01629   0.005267         49        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1083    0.01566   0.006112         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1042    0.01645    0.00513         38        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09853     0.0174   0.005819         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G     0.0917    0.01845   0.004377         45        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.08089    0.02072   0.005457         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07322    0.02373   0.004933         34        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06906    0.02417     0.0046         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06505     0.0248   0.005466         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06516    0.02342   0.004041         41        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.71it/s]\n",
            "                   all         23         23      0.866      0.726      0.802      0.395\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m15 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.86629,               0.7257,              0.80211,              0.39511,             0.082903,             0.011743,            0.0061789,                 0.01,                 0.01,                0.937,              0.00049,               3.0322,               0.7628,              0.09664,                 0.05,              0.51469,              0.93932,                    1,               1.0212,                  0.2,               3.8892,                    0,              0.01418,              0.75072,              0.38163,                    0,               0.1056,                  0.5,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.1327\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.93737, weight_decay=0.0005, warmup_epochs=2.98827, warmup_momentum=0.80801, warmup_bias_lr=0.10031, box=0.05062, cls=0.5, cls_pw=1.00154, obj=1.00756, obj_pw=1.00449, iou_t=0.2, anchor_t=4.027, fl_gamma=0.0, hsv_h=0.01487, hsv_s=0.69909, hsv_v=0.40314, degrees=0.0, translate=0.09947, scale=0.50113, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.99641, mixup=0.0, copy_paste=0.0, anchors=3.00222\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.00222\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 224.08it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 879.27it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1184    0.01624   0.005611         49        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G      0.109    0.01575   0.006022         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1043    0.01684   0.005162         39        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09841    0.01786   0.005354         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08978    0.02008   0.004998         34        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07895    0.02238   0.005456         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07121    0.02529   0.005075         34        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06839    0.02483   0.004493         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06498    0.02452   0.005475         37        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06513    0.02386    0.00475         40        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.72it/s]\n",
            "                   all         23         23      0.836      0.876      0.929      0.398\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m16 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m               0.836,              0.87584,              0.92918,              0.39843,             0.082072,             0.011494,            0.0055887,                 0.01,                 0.01,              0.93737,               0.0005,               2.9883,              0.80801,              0.10031,              0.05062,                  0.5,               1.0015,               1.0076,               1.0045,                  0.2,                4.027,                    0,              0.01487,              0.69909,              0.40314,                    0,              0.09947,              0.50113,                    0,                    0,                    0,                  0.5,              0.99641,                    0,                    0,               3.0022\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01107, momentum=0.91314, weight_decay=0.00051, warmup_epochs=3.60672, warmup_momentum=0.7311, warmup_bias_lr=0.0917, box=0.05195, cls=0.5, cls_pw=0.8779, obj=0.97202, obj_pw=0.96236, iou_t=0.2, anchor_t=4.41094, fl_gamma=0.0, hsv_h=0.01466, hsv_s=0.7, hsv_v=0.40539, degrees=0.0, translate=0.1, scale=0.53817, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.87797\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.87797\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005578125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 214.67it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 770.00it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 8.98 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1222    0.01597   0.004963         48        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1136    0.01545    0.00582         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1094    0.01602   0.004771         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G     0.1033    0.01688    0.00557         41        416: 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G     0.0965    0.01808   0.004274         43        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.08614    0.02028   0.005311         38        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.07816    0.02315   0.004732         34        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G     0.0734    0.02389   0.004658         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06879    0.02446   0.005378         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06885    0.02302   0.004071         39        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.91it/s]\n",
            "                   all         23         23        0.8      0.723      0.805      0.371\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m17 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.79997,              0.72267,              0.80456,              0.37106,             0.086823,             0.011439,            0.0058916,                 0.01,              0.01107,              0.91314,              0.00051,               3.6067,               0.7311,               0.0917,              0.05195,                  0.5,               0.8779,              0.97202,              0.96236,                  0.2,               4.4109,                    0,              0.01466,                  0.7,              0.40539,                    0,                  0.1,              0.53817,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                2.878\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01003, lrf=0.01, momentum=0.9397, weight_decay=0.0005, warmup_epochs=3.02938, warmup_momentum=0.80611, warmup_bias_lr=0.10064, box=0.05, cls=0.50396, cls_pw=0.99359, obj=1.01397, obj_pw=1.00582, iou_t=0.2, anchor_t=4.03225, fl_gamma=0.0, hsv_h=0.01506, hsv_s=0.70415, hsv_v=0.40527, degrees=0.0, translate=0.09968, scale=0.50521, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.99186, mixup=0.0, copy_paste=0.0, anchors=3.00844\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.00844\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01003) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 216.33it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 742.17it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G      0.117    0.01623   0.005933         41        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1079    0.01577   0.005587         43        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1026    0.01719     0.0055         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09707    0.01755   0.005626         47        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08939    0.01982    0.00544         35        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07806    0.02318   0.004171         52        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.07001      0.024   0.004285         44        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06703     0.0259   0.004277         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06392    0.02513   0.004201         37        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06281    0.02415   0.004403         41        416: 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.40it/s]\n",
            "                   all         23         23      0.734      0.603      0.744      0.312\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m18 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.73417,              0.60294,              0.74371,              0.31162,             0.082329,             0.011616,            0.0057812,              0.01003,                 0.01,               0.9397,               0.0005,               3.0294,              0.80611,              0.10064,                 0.05,              0.50396,              0.99359,                1.014,               1.0058,                  0.2,               4.0323,                    0,              0.01506,              0.70415,              0.40527,                    0,              0.09968,              0.50521,                    0,                    0,                    0,                  0.5,              0.99186,                    0,                    0,               3.0084\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01079, momentum=0.93186, weight_decay=0.00053, warmup_epochs=3.0, warmup_momentum=0.69345, warmup_bias_lr=0.10209, box=0.04854, cls=0.44558, cls_pw=1.0, obj=0.89476, obj_pw=0.92175, iou_t=0.2, anchor_t=4.0051, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.59683, hsv_v=0.42106, degrees=0.0, translate=0.08656, scale=0.47807, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98666, mixup=0.0, copy_paste=0.0, anchors=3.02932\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.02932\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005796875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 213.35it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 875.21it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1138    0.01353   0.005879         37        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1053    0.01302    0.00538         38        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1021    0.01374   0.005383         41        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09711    0.01424   0.005303         48        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.09356     0.0151   0.004812         36        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.08462    0.01685   0.004087         49        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07557    0.01861   0.004005         44        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06938    0.02009   0.003852         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06547    0.01999   0.003979         36        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06332    0.01957    0.00433         39        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.85it/s]\n",
            "                   all         23         23      0.679      0.574      0.643      0.309\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m19 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.67882,              0.57353,              0.64276,              0.30919,             0.083207,            0.0097702,            0.0056675,                 0.01,              0.01079,              0.93186,              0.00053,                    3,              0.69345,              0.10209,              0.04854,              0.44558,                    1,              0.89476,              0.92175,                  0.2,               4.0051,                    0,                0.015,              0.59683,              0.42106,                    0,              0.08656,              0.47807,                    0,                    0,                    0,                  0.5,              0.98666,                    0,                    0,               3.0293\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00884, lrf=0.01355, momentum=0.92604, weight_decay=0.00054, warmup_epochs=2.74744, warmup_momentum=0.85579, warmup_bias_lr=0.1, box=0.0695, cls=0.5, cls_pw=1.0, obj=1.32975, obj_pw=1.0, iou_t=0.2, anchor_t=3.42293, fl_gamma=0.0, hsv_h=0.01337, hsv_s=0.51107, hsv_v=0.4552, degrees=0.0, translate=0.11738, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.93488, mixup=0.0, copy_paste=0.0, anchors=3.04513\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.04513\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00884) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000590625), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 210.10it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 902.61it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 8.84 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.593-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1586    0.02032   0.006747         30        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1479    0.02008   0.005484         44        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1379    0.01955   0.005804         36        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.1278    0.02204   0.005151         40        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G     0.1077    0.02637   0.005233         46        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.09623    0.02823   0.005301         32        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G     0.0915    0.03002   0.005004         35        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.08693    0.02899   0.004732         33        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G     0.0847    0.02952   0.004326         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.08446    0.02867   0.006111         34        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.84it/s]\n",
            "                   all         23         23      0.861       0.77      0.895      0.427\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m20 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.86122,              0.76978,              0.89518,              0.42715,              0.10642,             0.014841,            0.0074196,              0.00884,              0.01355,              0.92604,              0.00054,               2.7474,              0.85579,                  0.1,               0.0695,                  0.5,                    1,               1.3297,                    1,                  0.2,               3.4229,                    0,              0.01337,              0.51107,               0.4552,                    0,              0.11738,                  0.5,                    0,                    0,                    0,                  0.5,              0.93488,                    0,                    0,               3.0451\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01019, lrf=0.01, momentum=0.9401, weight_decay=0.00046, warmup_epochs=3.0328, warmup_momentum=0.93342, warmup_bias_lr=0.0949, box=0.05418, cls=0.42291, cls_pw=1.10704, obj=1.14401, obj_pw=1.01521, iou_t=0.2, anchor_t=4.80367, fl_gamma=0.0, hsv_h=0.01559, hsv_s=0.62416, hsv_v=0.40863, degrees=0.0, translate=0.1, scale=0.4313, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.90979, mixup=0.0, copy_paste=0.0, anchors=2.64665\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.64665\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01019) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000503125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 220.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 887.62it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.21: 1.0000 best possible recall, 9.00 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.587-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1254    0.01822   0.005606         29        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1178    0.01785   0.005558         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1084    0.02097   0.004465         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09854    0.02401   0.005217         44        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08404    0.02824   0.004742         42        416: 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07683    0.03031    0.00625         37        416: 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07164    0.03004   0.004631         33        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06928    0.02995   0.004516         40        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06672    0.03135   0.003732         34        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G      0.065    0.03026   0.004441         35        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.85it/s]\n",
            "                   all         23         23      0.707      0.691      0.674      0.311\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m21 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.70715,              0.69118,              0.67421,              0.31103,             0.070917,             0.017914,             0.011144,              0.01019,                 0.01,               0.9401,              0.00046,               3.0328,              0.93342,               0.0949,              0.05418,              0.42291,                1.107,                1.144,               1.0152,                  0.2,               4.8037,                    0,              0.01559,              0.62416,              0.40863,                    0,                  0.1,               0.4313,                    0,                    0,                    0,                  0.5,              0.90979,                    0,                    0,               2.6467\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01055, lrf=0.01, momentum=0.96212, weight_decay=0.00049, warmup_epochs=3.07355, warmup_momentum=0.83039, warmup_bias_lr=0.10109, box=0.05086, cls=0.49134, cls_pw=1.01999, obj=1.0144, obj_pw=1.01506, iou_t=0.2, anchor_t=4.26634, fl_gamma=0.0, hsv_h=0.01487, hsv_s=0.74194, hsv_v=0.39196, degrees=0.0, translate=0.09976, scale=0.4875, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98821, mixup=0.0, copy_paste=0.0, anchors=2.8018\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.8018\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01055) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 216.17it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 863.99it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 8.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1188    0.01633   0.006705         38        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1098    0.01621   0.005959         38        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1042    0.01754   0.006006         37        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09683    0.01894   0.005924         48        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08671    0.02205   0.005272         36        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07551    0.02537   0.004265         49        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G     0.0703     0.0256    0.00451         44        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06692    0.02678   0.004161         42        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06461    0.02601   0.004031         36        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06383    0.02484   0.004508         39        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.79it/s]\n",
            "                   all         23         23      0.782      0.662      0.796      0.371\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m22 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.78182,              0.66176,              0.79618,               0.3705,             0.080738,             0.012059,            0.0060771,              0.01055,                 0.01,              0.96212,              0.00049,               3.0736,              0.83039,              0.10109,              0.05086,              0.49134,                 1.02,               1.0144,               1.0151,                  0.2,               4.2663,                    0,              0.01487,              0.74194,              0.39196,                    0,              0.09976,               0.4875,                    0,                    0,                    0,                  0.5,              0.98821,                    0,                    0,               2.8018\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00962, lrf=0.01, momentum=0.98, weight_decay=0.00046, warmup_epochs=3.0328, warmup_momentum=0.81718, warmup_bias_lr=0.09628, box=0.05, cls=0.55314, cls_pw=1.20129, obj=1.05418, obj_pw=1.2157, iou_t=0.2, anchor_t=4.03052, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.72478, hsv_v=0.42188, degrees=0.0, translate=0.09614, scale=0.54071, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.93864\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.93864\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00962) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000503125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:01<00:00, 165.72it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 573.64it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G      0.117     0.0192   0.006547         48        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1084    0.01904   0.007511         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1038    0.02013   0.006163         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09744    0.02156   0.006934         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08785    0.02421   0.004994         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07829     0.0267   0.006403         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07125    0.02973   0.005647         34        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06788       0.03    0.00531         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06395    0.03078   0.006307         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06439    0.02866   0.004514         39        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.58it/s]\n",
            "                   all         23         23      0.888      0.755      0.916      0.437\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m23 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.88767,              0.75549,              0.91625,              0.43724,              0.08104,             0.013935,            0.0072437,              0.00962,                 0.01,                 0.98,              0.00046,               3.0328,              0.81718,              0.09628,                 0.05,              0.55314,               1.2013,               1.0542,               1.2157,                  0.2,               4.0305,                    0,              0.01495,              0.72478,              0.42188,                    0,              0.09614,              0.54071,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.9386\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00992, lrf=0.01, momentum=0.93627, weight_decay=0.00054, warmup_epochs=2.99065, warmup_momentum=0.74294, warmup_bias_lr=0.09508, box=0.05184, cls=0.51765, cls_pw=1.03899, obj=0.95972, obj_pw=1.0, iou_t=0.2, anchor_t=3.8426, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.70881, hsv_v=0.37657, degrees=0.0, translate=0.09287, scale=0.46712, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.9422, mixup=0.0, copy_paste=0.0, anchors=2.75285\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.75285\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00992) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000590625), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 210.01it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 822.86it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.26: 1.0000 best possible recall, 8.93 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1203    0.01512   0.007011         30        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1119    0.01519    0.00606         44        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1076    0.01491      0.006         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.1016    0.01548   0.005692         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G     0.0954    0.01659   0.005595         46        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.08489    0.01947   0.005034         41        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07662    0.02185   0.005204         35        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.07033    0.02166   0.004862         44        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06831    0.02293   0.004098         46        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06666    0.02235   0.006074         35        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.65it/s]\n",
            "                   all         23         23      0.624      0.691       0.66      0.219\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m24 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.62393,              0.69118,              0.66003,              0.21878,             0.084465,             0.013522,              0.01302,              0.00992,                 0.01,              0.93627,              0.00054,               2.9907,              0.74294,              0.09508,              0.05184,              0.51765,                1.039,              0.95972,                    1,                  0.2,               3.8426,                    0,              0.01495,              0.70881,              0.37657,                    0,              0.09287,              0.46712,                    0,                    0,                    0,                  0.5,               0.9422,                    0,                    0,               2.7529\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01051, lrf=0.01, momentum=0.94605, weight_decay=0.00039, warmup_epochs=2.46094, warmup_momentum=0.78653, warmup_bias_lr=0.1, box=0.0529, cls=0.49134, cls_pw=0.86003, obj=0.7431, obj_pw=0.92329, iou_t=0.2, anchor_t=4.586, fl_gamma=0.0, hsv_h=0.01168, hsv_s=0.78829, hsv_v=0.45132, degrees=0.0, translate=0.1, scale=0.65627, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.83115, mixup=0.0, copy_paste=0.0, anchors=2.96451\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.96451\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01051) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.00042656249999999997), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 208.32it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 746.60it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 8.99 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.587-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.46G     0.1241    0.01094   0.005957         37        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.46G     0.1161    0.01116   0.005736         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.46G     0.1096    0.01114   0.005733         35        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.46G     0.1029    0.01246   0.004728         40        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.46G    0.09246    0.01383   0.004919         36        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.46G    0.08269    0.01565   0.004746         41        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.46G    0.07544    0.01696   0.004656         34        416: 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.46G    0.07358    0.01716   0.004442         37        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.46G    0.07093    0.01714   0.004395         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.46G    0.07097    0.01574   0.003916         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.82it/s]\n",
            "                   all         23         23      0.731        0.8      0.782      0.339\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m25 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.73106,              0.80029,              0.78176,              0.33875,             0.084101,            0.0096903,            0.0068868,              0.01051,                 0.01,              0.94605,              0.00039,               2.4609,              0.78653,                  0.1,               0.0529,              0.49134,              0.86003,               0.7431,              0.92329,                  0.2,                4.586,                    0,              0.01168,              0.78829,              0.45132,                    0,                  0.1,              0.65627,                    0,                    0,                    0,                  0.5,              0.83115,                    0,                    0,               2.9645\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00978, lrf=0.01, momentum=0.94834, weight_decay=0.00048, warmup_epochs=2.97198, warmup_momentum=0.81194, warmup_bias_lr=0.09844, box=0.0499, cls=0.49566, cls_pw=0.99999, obj=0.99995, obj_pw=1.00398, iou_t=0.2, anchor_t=4.08415, fl_gamma=0.0, hsv_h=0.01536, hsv_s=0.73728, hsv_v=0.41164, degrees=0.0, translate=0.10076, scale=0.50097, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.77695\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.77695\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00978) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000525), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 214.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 803.36it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.46G     0.1164    0.01647   0.005336         49        416: 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.46G      0.108    0.01587   0.006205         36        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.46G     0.1034    0.01676   0.005102         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.46G    0.09712    0.01783   0.005768         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.46G    0.08773    0.01988   0.004277         45        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.46G    0.07756    0.02206    0.00552         38        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.46G    0.07047    0.02463   0.004852         34        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.46G    0.06756    0.02497   0.004542         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.46G    0.06393    0.02532    0.00539         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.46G    0.06419    0.02397   0.004004         40        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.85it/s]\n",
            "                   all         23         23      0.881       0.77      0.894      0.449\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m26 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.88149,              0.77021,               0.8936,              0.44904,             0.081108,             0.011659,            0.0063363,              0.00978,                 0.01,              0.94834,              0.00048,                2.972,              0.81194,              0.09844,               0.0499,              0.49566,              0.99999,              0.99995,                1.004,                  0.2,               4.0842,                    0,              0.01536,              0.73728,              0.41164,                    0,              0.10076,              0.50097,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.7769\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00869, lrf=0.01199, momentum=0.95059, weight_decay=0.00052, warmup_epochs=3.29251, warmup_momentum=0.85976, warmup_bias_lr=0.11872, box=0.05, cls=0.53346, cls_pw=1.12816, obj=0.8643, obj_pw=0.95944, iou_t=0.2, anchor_t=2.9218, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.63339, hsv_v=0.4121, degrees=0.0, translate=0.06676, scale=0.52668, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.03865\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.03865\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00869) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005687499999999999), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 220.42it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 760.89it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 7.90 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.626-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1144    0.01233   0.005825         48        416: 100% 6/6 [00:04<00:00,  1.33it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1062    0.01138    0.00668         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1028    0.01135   0.005445         44        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09587    0.01225   0.005839         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08732    0.01335   0.004245         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07699    0.01471   0.005359         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G     0.0689    0.01671   0.004843         34        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06482    0.01672    0.00451         44        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06235    0.01683   0.005338         40        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G     0.0619    0.01617   0.003593         40        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.89it/s]\n",
            "                   all         23         23      0.798      0.713      0.828      0.411\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m27 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.79778,              0.71251,              0.82833,              0.41092,              0.08204,            0.0079889,            0.0063048,              0.00869,              0.01199,              0.95059,              0.00052,               3.2925,              0.85976,              0.11872,                 0.05,              0.53346,               1.1282,               0.8643,              0.95944,                  0.2,               2.9218,                    0,              0.01495,              0.63339,               0.4121,                    0,              0.06676,              0.52668,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.0387\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01, momentum=0.98, weight_decay=0.00057, warmup_epochs=3.0328, warmup_momentum=0.78685, warmup_bias_lr=0.11878, box=0.04991, cls=0.44535, cls_pw=0.7625, obj=0.92608, obj_pw=0.91194, iou_t=0.2, anchor_t=3.31466, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.61757, hsv_v=0.43463, degrees=0.0, translate=0.101, scale=0.4143, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.82088, mixup=0.0, copy_paste=0.0, anchors=2.49533\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.49533\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0006234375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.76it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 898.36it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.30: 1.0000 best possible recall, 5.88 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.590-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.46G    0.09217    0.02598    0.01927         38        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.46G    0.07191    0.02907    0.01779         40        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.46G    0.06103    0.02945    0.01579         36        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.46G    0.05472    0.03098    0.01363         37        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.46G    0.05347    0.03003    0.01183         37        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.46G    0.05211    0.02984    0.01001         34        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.46G    0.04997     0.0321    0.00893         39        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.46G    0.04872    0.02927   0.008707         39        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.46G    0.04852    0.02839   0.007581         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.46G    0.04636    0.02671   0.007351         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.50it/s]\n",
            "                   all         23         23      0.907      0.387      0.609      0.245\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m28 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.90718,              0.38731,              0.60894,              0.24546,             0.059771,             0.014881,             0.014075,              0.00991,                 0.01,                 0.98,              0.00057,               3.0328,              0.78685,              0.11878,              0.04991,              0.44535,               0.7625,              0.92608,              0.91194,                  0.2,               3.3147,                    0,              0.01495,              0.61757,              0.43463,                    0,                0.101,               0.4143,                    0,                    0,                    0,                  0.5,              0.82088,                    0,                    0,               2.4953\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01016, lrf=0.01, momentum=0.94605, weight_decay=0.00049, warmup_epochs=2.97485, warmup_momentum=0.81718, warmup_bias_lr=0.1018, box=0.05003, cls=0.49831, cls_pw=1.01235, obj=1.00747, obj_pw=1.00592, iou_t=0.2, anchor_t=4.0817, fl_gamma=0.0, hsv_h=0.01501, hsv_s=0.72233, hsv_v=0.40687, degrees=0.0, translate=0.1, scale=0.48876, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.97295\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.97295\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01016) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 207.42it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 839.79it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1165    0.01661    0.00534         49        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G      0.108    0.01607    0.00627         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1033    0.01694   0.005166         39        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.0967    0.01808   0.005776         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08647    0.02044   0.004277         45        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07644    0.02252   0.005561         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.06983    0.02511   0.004955         34        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06712    0.02526   0.004511         43        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06347    0.02559   0.005397         40        416: 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06428    0.02439   0.003978         41        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.62it/s]\n",
            "                   all         23         23        0.9       0.86      0.911      0.411\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m29 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.89956,              0.86001,              0.91108,              0.41052,             0.080491,             0.012004,            0.0071204,              0.01016,                 0.01,              0.94605,              0.00049,               2.9748,              0.81718,               0.1018,              0.05003,              0.49831,               1.0124,               1.0075,               1.0059,                  0.2,               4.0817,                    0,              0.01501,              0.72233,              0.40687,                    0,                  0.1,              0.48876,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.9729\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01142, momentum=0.95069, weight_decay=0.00039, warmup_epochs=2.68666, warmup_momentum=0.69803, warmup_bias_lr=0.10393, box=0.04877, cls=0.49134, cls_pw=0.92567, obj=0.82553, obj_pw=0.9828, iou_t=0.2, anchor_t=4.5876, fl_gamma=0.0, hsv_h=0.01354, hsv_s=0.72108, hsv_v=0.47199, degrees=0.0, translate=0.12775, scale=0.50107, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.50894\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.50894\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.00042656249999999997), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 214.53it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 770.13it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.22: 1.0000 best possible recall, 8.99 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.587-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1145    0.01379   0.005155         49        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1067    0.01356   0.006101         36        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G      0.103    0.01424   0.004986         38        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09784     0.0148   0.005726         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G     0.0924    0.01552   0.004527         43        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.08319    0.01716   0.005721         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07591    0.01971   0.004876         35        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.07034    0.02072   0.004681         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06574    0.02124   0.005376         40        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06608    0.02005   0.004159         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.67it/s]\n",
            "                   all         23         23      0.695      0.745       0.79      0.353\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m30 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.69494,               0.7451,              0.78951,              0.35272,             0.083044,             0.010566,            0.0068755,              0.00991,              0.01142,              0.95069,              0.00039,               2.6867,              0.69803,              0.10393,              0.04877,              0.49134,              0.92567,              0.82553,               0.9828,                  0.2,               4.5876,                    0,              0.01354,              0.72108,              0.47199,                    0,              0.12775,              0.50107,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.5089\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01035, lrf=0.01, momentum=0.93325, weight_decay=0.00049, warmup_epochs=3.16959, warmup_momentum=0.81597, warmup_bias_lr=0.10803, box=0.04787, cls=0.57615, cls_pw=1.05705, obj=1.01184, obj_pw=1.0, iou_t=0.2, anchor_t=4.27225, fl_gamma=0.0, hsv_h=0.01295, hsv_s=0.66528, hsv_v=0.34616, degrees=0.0, translate=0.11797, scale=0.49412, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.66826\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.66826\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01035) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 215.58it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 828.78it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 8.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1116    0.01671   0.006307         50        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1036    0.01646   0.007081         36        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.09865    0.01721   0.005817         38        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09245    0.01843   0.006584         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08258    0.02066   0.004684         44        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07329     0.0228   0.006486         38        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.06733    0.02519   0.005513         35        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06466    0.02565   0.004846         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06084    0.02583   0.005983         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06198    0.02417   0.004266         41        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.65it/s]\n",
            "                   all         23         23      0.823      0.721      0.854      0.391\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m31 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.82305,              0.72059,              0.85446,              0.39076,             0.075615,             0.012975,              0.01048,              0.01035,                 0.01,              0.93325,              0.00049,               3.1696,              0.81597,              0.10803,              0.04787,              0.57615,               1.0571,               1.0118,                    1,                  0.2,               4.2722,                    0,              0.01295,              0.66528,              0.34616,                    0,              0.11797,              0.49412,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.6683\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01041, lrf=0.01, momentum=0.95576, weight_decay=0.00049, warmup_epochs=3.11439, warmup_momentum=0.8177, warmup_bias_lr=0.10303, box=0.05, cls=0.51862, cls_pw=1.0175, obj=1.00913, obj_pw=1.0, iou_t=0.2, anchor_t=4.29352, fl_gamma=0.0, hsv_h=0.01485, hsv_s=0.71879, hsv_v=0.38656, degrees=0.0, translate=0.10148, scale=0.48851, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.8572\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.8572\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01041) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 214.66it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 771.88it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 8.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1166    0.01683    0.00563         49        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1082     0.0164   0.006465         36        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1031    0.01728   0.005316         38        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09624    0.01858   0.005905         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08501    0.02112     0.0044         45        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07524     0.0232   0.005796         38        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.06967    0.02555   0.005115         34        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06708    0.02583   0.004715         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06341    0.02606   0.005554         40        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G     0.0644    0.02465   0.004047         41        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.61it/s]\n",
            "                   all         23         23      0.762      0.804      0.897      0.428\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m32 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.76199,              0.80392,              0.89685,               0.4276,             0.079101,             0.012452,            0.0078633,              0.01041,                 0.01,              0.95576,              0.00049,               3.1144,               0.8177,              0.10303,                 0.05,              0.51862,               1.0175,               1.0091,                    1,                  0.2,               4.2935,                    0,              0.01485,              0.71879,              0.38656,                    0,              0.10148,              0.48851,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.8572\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01009, momentum=0.94029, weight_decay=0.0005, warmup_epochs=3.0328, warmup_momentum=0.81392, warmup_bias_lr=0.09868, box=0.0492, cls=0.5092, cls_pw=1.0175, obj=1.05541, obj_pw=1.02003, iou_t=0.2, anchor_t=4.02714, fl_gamma=0.0, hsv_h=0.01519, hsv_s=0.70529, hsv_v=0.39725, degrees=0.0, translate=0.10082, scale=0.50538, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.98712, mixup=0.0, copy_paste=0.0, anchors=2.8018\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.8018\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 210.75it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 786.40it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1153    0.01668   0.006839         38        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1061    0.01635   0.006135         38        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1018    0.01769   0.006251         38        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.0954    0.01852   0.005982         48        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08837    0.02088   0.005329         35        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07693    0.02448   0.004292         49        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.06945     0.0252   0.004347         44        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06591     0.0267   0.004175         42        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G     0.0633    0.02613   0.004176         36        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06221    0.02496   0.004515         38        416: 100% 6/6 [00:04<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "                   all         23         23      0.502      0.882      0.747      0.314\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m33 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.50225,              0.88235,              0.74678,              0.31439,             0.081318,             0.012113,            0.0061284,              0.00991,              0.01009,              0.94029,               0.0005,               3.0328,              0.81392,              0.09868,               0.0492,               0.5092,               1.0175,               1.0554,                 1.02,                  0.2,               4.0271,                    0,              0.01519,              0.70529,              0.39725,                    0,              0.10082,              0.50538,                    0,                    0,                    0,                  0.5,              0.98712,                    0,                    0,               2.8018\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0074, lrf=0.01, momentum=0.94605, weight_decay=0.00053, warmup_epochs=2.75812, warmup_momentum=0.76858, warmup_bias_lr=0.09143, box=0.06013, cls=0.48535, cls_pw=1.0175, obj=1.09717, obj_pw=0.78939, iou_t=0.2, anchor_t=4.17955, fl_gamma=0.0, hsv_h=0.01536, hsv_s=0.71879, hsv_v=0.35767, degrees=0.0, translate=0.07962, scale=0.49412, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.11647\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.11647\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0074) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005796875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 214.07it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 741.10it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1402    0.01604   0.005223         48        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1302    0.01515   0.006077         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1253    0.01564   0.005114         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G      0.118    0.01626    0.00579         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G     0.1098    0.01746   0.004434         44        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.09824    0.01935   0.005398         38        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.08909    0.02199   0.004871         34        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.08349    0.02269   0.004633         43        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.07847    0.02338   0.005607         40        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.07844    0.02235   0.004189         39        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.51it/s]\n",
            "                   all         23         23      0.823      0.784      0.829      0.389\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m34 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.82345,              0.78403,              0.82925,              0.38907,              0.10125,             0.010847,             0.006299,               0.0074,                 0.01,              0.94605,              0.00053,               2.7581,              0.76858,              0.09143,              0.06013,              0.48535,               1.0175,               1.0972,              0.78939,                  0.2,               4.1795,                    0,              0.01536,              0.71879,              0.35767,                    0,              0.07962,              0.49412,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.1165\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0101, lrf=0.01002, momentum=0.94815, weight_decay=0.00049, warmup_epochs=3.01333, warmup_momentum=0.81672, warmup_bias_lr=0.10059, box=0.04941, cls=0.50006, cls_pw=0.99262, obj=1.01305, obj_pw=1.00886, iou_t=0.2, anchor_t=4.0234, fl_gamma=0.0, hsv_h=0.01446, hsv_s=0.68667, hsv_v=0.40812, degrees=0.0, translate=0.10251, scale=0.49307, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.74419\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.74419\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0101) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 212.90it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 817.40it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1152    0.01664   0.005304         49        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1067    0.01603   0.006198         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1021    0.01696   0.005152         38        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09587    0.01803   0.005656         41        416: 100% 6/6 [00:04<00:00,  1.47it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08581    0.02027   0.004208         45        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07576    0.02232   0.005476         38        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.06908    0.02497   0.004859         34        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06629    0.02505   0.004473         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06279    0.02544   0.005252         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06341    0.02425   0.003878         41        416: 100% 6/6 [00:04<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.64it/s]\n",
            "                   all         23         23      0.876      0.847      0.888      0.438\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m35 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.87638,              0.84731,              0.88808,              0.43804,             0.080014,             0.011813,            0.0065822,               0.0101,              0.01002,              0.94815,              0.00049,               3.0133,              0.81672,              0.10059,              0.04941,              0.50006,              0.99262,               1.0131,               1.0089,                  0.2,               4.0234,                    0,              0.01446,              0.68667,              0.40812,                    0,              0.10251,              0.49307,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.7442\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00997, lrf=0.01, momentum=0.94896, weight_decay=0.00049, warmup_epochs=3.02287, warmup_momentum=0.81718, warmup_bias_lr=0.1, box=0.04985, cls=0.49134, cls_pw=1.01387, obj=1.00948, obj_pw=1.00253, iou_t=0.2, anchor_t=4.08468, fl_gamma=0.0, hsv_h=0.01499, hsv_s=0.71879, hsv_v=0.40918, degrees=0.0, translate=0.09963, scale=0.49435, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.78897\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.78897\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00997) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 212.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 704.08it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1162    0.01665   0.005289         49        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1078    0.01606   0.006198         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1031    0.01691     0.0051         39        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09668      0.018   0.005736         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08674    0.02031   0.004229         45        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07659    0.02242   0.005513         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.06984    0.02506   0.004894         34        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06714    0.02515   0.004465         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06348    0.02554   0.005331         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06418    0.02431   0.003961         41        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.48it/s]\n",
            "                   all         23         23      0.908      0.796      0.928      0.455\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m36 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.90792,              0.79617,              0.92772,              0.45485,             0.080664,              0.01174,            0.0063791,              0.00997,                 0.01,              0.94896,              0.00049,               3.0229,              0.81718,                  0.1,              0.04985,              0.49134,               1.0139,               1.0095,               1.0025,                  0.2,               4.0847,                    0,              0.01499,              0.71879,              0.40918,                    0,              0.09963,              0.49435,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                2.789\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00874, lrf=0.01175, momentum=0.94605, weight_decay=0.00046, warmup_epochs=2.67201, warmup_momentum=0.93252, warmup_bias_lr=0.09441, box=0.04725, cls=0.42785, cls_pw=1.108, obj=1.03359, obj_pw=1.0, iou_t=0.2, anchor_t=4.36193, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.68321, hsv_v=0.41106, degrees=0.0, translate=0.10694, scale=0.49849, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.449\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.449\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00874) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000503125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 212.27it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 770.82it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 5.98 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.584-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.0963    0.03336     0.0237         49        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G    0.07818    0.03723     0.0212         36        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.06292     0.0437      0.017         38        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.05588    0.04447    0.01357         41        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.05184    0.04473   0.009965         45        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.04992    0.04112   0.009177         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.04974    0.04007   0.007122         34        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.04729     0.0392   0.006016         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.04381    0.03947   0.006297         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.04374    0.03725   0.005087         41        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.53it/s]\n",
            "                   all         23         23      0.899      0.412       0.59      0.223\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m37 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.89855,              0.41176,              0.59029,               0.2231,             0.063719,             0.016392,             0.011331,              0.00874,              0.01175,              0.94605,              0.00046,                2.672,              0.93252,              0.09441,              0.04725,              0.42785,                1.108,               1.0336,                    1,                  0.2,               4.3619,                    0,              0.01495,              0.68321,              0.41106,                    0,              0.10694,              0.49849,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                2.449\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0103, lrf=0.01074, momentum=0.94605, weight_decay=0.00048, warmup_epochs=2.83437, warmup_momentum=0.81718, warmup_bias_lr=0.0892, box=0.05, cls=0.49795, cls_pw=0.96678, obj=1.02255, obj_pw=0.96783, iou_t=0.2, anchor_t=4.2356, fl_gamma=0.0, hsv_h=0.0146, hsv_s=0.73841, hsv_v=0.46252, degrees=0.0, translate=0.1, scale=0.52793, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.84344\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.84344\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0103) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000525), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:01<00:00, 181.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 530.37it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.588-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1173    0.01662   0.005292         48        416: 100% 6/6 [00:04<00:00,  1.46it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1088    0.01603   0.006143         36        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1041    0.01689   0.005127         39        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.09754    0.01809   0.005713         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08748    0.02042   0.004339         43        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07727    0.02274   0.005643         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07089    0.02509   0.004995         34        416: 100% 6/6 [00:03<00:00,  1.52it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06797    0.02535   0.004743         43        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G     0.0645    0.02582   0.005429         40        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06486    0.02409   0.004031         39        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.58it/s]\n",
            "                   all         23         23      0.918       0.84      0.955      0.423\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m38 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.91796,              0.83973,                0.955,              0.42332,             0.081254,             0.012151,            0.0068265,               0.0103,              0.01074,              0.94605,              0.00048,               2.8344,              0.81718,               0.0892,                 0.05,              0.49795,              0.96678,               1.0226,              0.96783,                  0.2,               4.2356,                    0,               0.0146,              0.73841,              0.46252,                    0,                  0.1,              0.52793,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.8434\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.0104, momentum=0.94605, weight_decay=0.00066, warmup_epochs=3.0328, warmup_momentum=0.72129, warmup_bias_lr=0.07013, box=0.05893, cls=0.58684, cls_pw=1.10383, obj=1.00728, obj_pw=1.04434, iou_t=0.2, anchor_t=4.11133, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.74219, hsv_v=0.42018, degrees=0.0, translate=0.1, scale=0.50414, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.705\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.705\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000721875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 209.58it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 954.13it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.95 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.589-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1385    0.01694   0.006682         49        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1287    0.01642    0.00784         36        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1239     0.0173   0.006429         39        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G     0.1174     0.0182    0.00739         41        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G     0.1087    0.01956   0.005586         44        416: 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.09579    0.02213   0.007076         38        416: 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.08608     0.0253   0.006261         34        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G      0.082    0.02578   0.005854         43        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.07727    0.02628   0.006943         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.07735    0.02502   0.005181         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.99it/s]\n",
            "                   all         23         23      0.854      0.718      0.806      0.392\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m39 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.85391,              0.71768,              0.80647,                0.392,             0.098688,             0.012388,            0.0078937,              0.00991,               0.0104,              0.94605,              0.00066,               3.0328,              0.72129,              0.07013,              0.05893,              0.58684,               1.1038,               1.0073,               1.0443,                  0.2,               4.1113,                    0,              0.01495,              0.74219,              0.42018,                    0,                  0.1,              0.50414,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                2.705\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01053, lrf=0.01, momentum=0.98, weight_decay=0.00043, warmup_epochs=2.36223, warmup_momentum=0.77853, warmup_bias_lr=0.08097, box=0.04854, cls=0.51981, cls_pw=1.0175, obj=0.94958, obj_pw=0.95329, iou_t=0.2, anchor_t=4.0817, fl_gamma=0.0, hsv_h=0.01427, hsv_s=0.71879, hsv_v=0.45506, degrees=0.0, translate=0.11798, scale=0.46695, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.65525\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.65525\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     50260  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46156244 parameters, 46156244 gradients, 108.3 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01053) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0004703125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 214.42it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 12 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9201: 100% 1000/1000 [00:01<00:00, 796.82it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 11.93 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=12, img_size=416, metric_all=0.584/0.920-mean/best, past_thr=0.586-mean: 122,373, 374,131, 146,337, 281,211, 363,186, 187,400, 395,202, 252,338, 231,380, 364,251, 411,246, 311,414\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.44G    0.09849    0.02808    0.02744         49        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.44G    0.08581    0.03001    0.02634         35        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.44G    0.07351    0.03393    0.02434         38        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.44G    0.06303    0.03727    0.02238         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.44G    0.05776    0.03916    0.01982         44        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.44G    0.05553    0.03809    0.01838         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.44G    0.05291    0.03917    0.01618         35        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.44G    0.05196    0.03746    0.01425         42        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.44G    0.04901    0.03808    0.01322         40        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.44G    0.04922    0.03546    0.01142         40        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.49it/s]\n",
            "                   all         23         23      0.726      0.471      0.473      0.237\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m40 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.72622,              0.47059,               0.4734,              0.23746,             0.064116,             0.016725,             0.018976,              0.01053,                 0.01,                 0.98,              0.00043,               2.3622,              0.77853,              0.08097,              0.04854,              0.51981,               1.0175,              0.94958,              0.95329,                  0.2,               4.0817,                    0,              0.01427,              0.71879,              0.45506,                    0,              0.11798,              0.46695,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.6553\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00992, lrf=0.01013, momentum=0.9492, weight_decay=0.00048, warmup_epochs=3.04892, warmup_momentum=0.81842, warmup_bias_lr=0.1, box=0.05069, cls=0.50212, cls_pw=1.00681, obj=0.99548, obj_pw=0.95768, iou_t=0.2, anchor_t=4.0711, fl_gamma=0.0, hsv_h=0.01483, hsv_s=0.71879, hsv_v=0.40163, degrees=0.0, translate=0.1, scale=0.49312, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.96195, mixup=0.0, copy_paste=0.0, anchors=2.71889\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.71889\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00992) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000525), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 205.06it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 821.03it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.49G     0.1182     0.0152   0.006764         38        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.49G     0.1094    0.01574   0.006147         46        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.49G     0.1041    0.01583   0.005534         32        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.49G    0.09824    0.01699    0.00588         44        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.49G    0.08959    0.01901    0.00479         38        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.49G    0.07825    0.02199   0.004866         41        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.49G    0.07017    0.02406   0.004618         48        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.49G    0.06809    0.02312   0.004571         33        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.49G    0.06579     0.0233   0.004874         31        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.49G    0.06395    0.02367   0.005025         31        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.62it/s]\n",
            "                   all         23         23      0.842       0.73      0.782       0.32\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m41 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.84197,              0.73007,              0.78208,              0.31951,             0.082067,             0.012402,            0.0082641,              0.00992,              0.01013,               0.9492,              0.00048,               3.0489,              0.81842,                  0.1,              0.05069,              0.50212,               1.0068,              0.99548,              0.95768,                  0.2,               4.0711,                    0,              0.01483,              0.71879,              0.40163,                    0,                  0.1,              0.49312,                    0,                    0,                    0,                  0.5,              0.96195,                    0,                    0,               2.7189\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01129, momentum=0.89591, weight_decay=0.00045, warmup_epochs=3.0328, warmup_momentum=0.87493, warmup_bias_lr=0.1, box=0.04837, cls=0.4786, cls_pw=0.89206, obj=0.9448, obj_pw=0.87005, iou_t=0.2, anchor_t=3.9474, fl_gamma=0.0, hsv_h=0.01689, hsv_s=0.78081, hsv_v=0.4351, degrees=0.0, translate=0.08815, scale=0.49412, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=3.3538\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=3.3538\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0004921875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 209.59it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 860.74it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.93 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1126    0.01429   0.004853         48        416: 100% 6/6 [00:04<00:00,  1.39it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1043    0.01348   0.005594         36        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G    0.09932    0.01427   0.004733         41        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09288    0.01537   0.005137         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08123    0.01774    0.00384         44        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07221    0.01921   0.005004         38        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.06644     0.0211   0.004411         34        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06443    0.02114   0.004109         43        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06105    0.02151   0.004961         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G    0.06154    0.02035    0.00353         39        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.68it/s]\n",
            "                   all         23         23      0.825      0.888      0.873       0.34\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m42 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.82544,              0.88751,               0.8731,              0.34008,             0.077189,             0.010749,            0.0077593,              0.00991,              0.01129,              0.89591,              0.00045,               3.0328,              0.87493,                  0.1,              0.04837,               0.4786,              0.89206,               0.9448,              0.87005,                  0.2,               3.9474,                    0,              0.01689,              0.78081,               0.4351,                    0,              0.08815,              0.49412,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               3.3538\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01117, lrf=0.01119, momentum=0.92855, weight_decay=0.00041, warmup_epochs=2.88583, warmup_momentum=0.95, warmup_bias_lr=0.1, box=0.06203, cls=0.51701, cls_pw=0.88392, obj=0.78916, obj_pw=0.86751, iou_t=0.2, anchor_t=3.40243, fl_gamma=0.0, hsv_h=0.0176, hsv_s=0.51952, hsv_v=0.40278, degrees=0.0, translate=0.10153, scale=0.46104, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.8018\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.8018\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01117) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0004484375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 205.76it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 845.62it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 8.83 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.593-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1423    0.01154   0.004945         49        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G     0.1326    0.01049   0.005674         34        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G     0.1211    0.01206   0.004777         38        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.1062    0.01479    0.00496         41        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.08825    0.01684   0.004076         43        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.08027    0.01719   0.005366         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.07894    0.01775   0.004428         35        416: 100% 6/6 [00:04<00:00,  1.45it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.07606    0.01788   0.004006         42        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G     0.0671    0.01949   0.004997         40        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.06218    0.01973   0.003268         41        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.67it/s]\n",
            "                   all         23         23      0.429        0.6      0.459      0.126\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m43 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.42864,              0.60012,               0.4594,              0.12597,              0.09211,             0.010246,             0.016366,              0.01117,              0.01119,              0.92855,              0.00041,               2.8858,                 0.95,                  0.1,              0.06203,              0.51701,              0.88392,              0.78916,              0.86751,                  0.2,               3.4024,                    0,               0.0176,              0.51952,              0.40278,                    0,              0.10153,              0.46104,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.8018\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01068, lrf=0.01, momentum=0.9456, weight_decay=0.00049, warmup_epochs=2.61869, warmup_momentum=0.83974, warmup_bias_lr=0.1, box=0.04801, cls=0.51605, cls_pw=0.95516, obj=1.00259, obj_pw=1.02991, iou_t=0.2, anchor_t=4.20943, fl_gamma=0.0, hsv_h=0.01468, hsv_s=0.71215, hsv_v=0.40863, degrees=0.0, translate=0.10347, scale=0.43883, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.19949\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.19949\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01068) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 213.93it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 931.96it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 5.96 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.585-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G    0.09656     0.0331    0.02571         49        416: 100% 6/6 [00:03<00:00,  1.53it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G    0.07722    0.03727    0.02327         34        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.06079     0.0437     0.0194         38        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.05564    0.04388    0.01618         41        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.05212    0.04404    0.01254         43        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.05106    0.04017     0.0115         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G       0.05     0.0399   0.009304         35        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.04872    0.03818   0.008081         42        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.04524    0.03863   0.008047         39        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.04472    0.03688   0.006841         41        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.53it/s]\n",
            "                   all         23         23      0.943      0.456      0.829      0.444\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m44 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.94284,              0.45613,              0.82863,              0.44401,             0.058199,             0.017891,              0.01603,              0.01068,                 0.01,               0.9456,              0.00049,               2.6187,              0.83974,                  0.1,              0.04801,              0.51605,              0.95516,               1.0026,               1.0299,                  0.2,               4.2094,                    0,              0.01468,              0.71215,              0.40863,                    0,              0.10347,              0.43883,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.1995\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00943, lrf=0.01093, momentum=0.93809, weight_decay=0.00051, warmup_epochs=2.79528, warmup_momentum=0.79783, warmup_bias_lr=0.09924, box=0.05, cls=0.53551, cls_pw=0.93657, obj=1.0041, obj_pw=1.05737, iou_t=0.2, anchor_t=4.32715, fl_gamma=0.0, hsv_h=0.01428, hsv_s=0.71879, hsv_v=0.40863, degrees=0.0, translate=0.1, scale=0.51391, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.95416, mixup=0.0, copy_paste=0.0, anchors=2.39772\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.39772\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00943) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005578125), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 206.49it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 769.95it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 5.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.584-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1018    0.03291     0.0265         38        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G    0.08254    0.03798     0.0243         46        416: 100% 6/6 [00:03<00:00,  1.64it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.06579    0.04336    0.02106         37        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.05912    0.04426    0.01795         38        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.05675    0.04476     0.0154         44        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.05427     0.0442    0.01284         43        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.05242    0.04261    0.01093         37        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.05206    0.03989    0.00958         41        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G     0.0496    0.03991   0.008984         44        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.04548    0.04024   0.008595         30        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.21it/s]\n",
            "                   all         23         23      0.841      0.382      0.434      0.182\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m45 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.84109,              0.38235,              0.43376,              0.18179,             0.065093,             0.019818,             0.020209,              0.00943,              0.01093,              0.93809,              0.00051,               2.7953,              0.79783,              0.09924,                 0.05,              0.53551,              0.93657,               1.0041,               1.0574,                  0.2,               4.3271,                    0,              0.01428,              0.71879,              0.40863,                    0,                  0.1,              0.51391,                    0,                    0,                    0,                  0.5,              0.95416,                    0,                    0,               2.3977\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01167, lrf=0.01, momentum=0.98, weight_decay=0.00055, warmup_epochs=3.0328, warmup_momentum=0.66476, warmup_bias_lr=0.07689, box=0.06363, cls=0.46017, cls_pw=0.92696, obj=0.99327, obj_pw=1.0, iou_t=0.2, anchor_t=4.33183, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.71879, hsv_v=0.49805, degrees=0.0, translate=0.11404, scale=0.46919, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.85959, mixup=0.0, copy_paste=0.0, anchors=2.22655\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.22655\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01167) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0006015625), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 205.48it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 788.76it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 1.0000 best possible recall, 5.97 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.584-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1254    0.03013    0.02253         31        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G      0.102    0.03343    0.02125         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.08176    0.04092    0.01964         38        416: 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G     0.0769    0.03979    0.01797         37        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.07399    0.04054    0.01608         39        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.07078    0.04021    0.01426         37        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.06829    0.04049    0.01293         37        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.06683     0.0377    0.01162         31        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.06358    0.04004    0.01119         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.05929    0.03831   0.009311         37        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.65it/s]\n",
            "                   all         23         23       0.92      0.464      0.557      0.257\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m46 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m                0.92,              0.46356,              0.55716,              0.25696,             0.079739,             0.018381,             0.015925,              0.01167,                 0.01,                 0.98,              0.00055,               3.0328,              0.66476,              0.07689,              0.06363,              0.46017,              0.92696,              0.99327,                    1,                  0.2,               4.3318,                    0,              0.01495,              0.71879,              0.49805,                    0,              0.11404,              0.46919,                    0,                    0,                    0,                  0.5,              0.85959,                    0,                    0,               2.2266\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00924, lrf=0.01, momentum=0.97224, weight_decay=0.00039, warmup_epochs=3.15532, warmup_momentum=0.81718, warmup_bias_lr=0.09982, box=0.05762, cls=0.35787, cls_pw=0.88618, obj=1.0041, obj_pw=0.9148, iou_t=0.2, anchor_t=3.98458, fl_gamma=0.0, hsv_h=0.01636, hsv_s=0.83912, hsv_v=0.4026, degrees=0.0, translate=0.1103, scale=0.49181, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00924) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.00042656249999999997), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 210.55it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 885.97it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 5.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.586-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.47G     0.1152    0.03032    0.01711         50        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.47G    0.09153    0.03332    0.01618         36        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.47G    0.07222    0.03923    0.01456         38        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.47G    0.06607    0.04012    0.01302         41        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.47G    0.06242    0.04052    0.01113         45        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.47G    0.05965    0.03843    0.01023         38        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.47G    0.05901    0.03819   0.008885         34        416: 100% 6/6 [00:03<00:00,  1.54it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.47G    0.05746    0.03654    0.00784         43        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.47G    0.05351    0.03685   0.007477         40        416: 100% 6/6 [00:04<00:00,  1.48it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.47G    0.05373    0.03474   0.006698         41        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.53it/s]\n",
            "                   all         23         23      0.866      0.471      0.564      0.226\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m47 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.86603,              0.47059,              0.56375,              0.22559,             0.072068,             0.016112,              0.01216,              0.00924,                 0.01,              0.97224,              0.00039,               3.1553,              0.81718,              0.09982,              0.05762,              0.35787,              0.88618,               1.0041,               0.9148,                  0.2,               3.9846,                    0,              0.01636,              0.83912,               0.4026,                    0,               0.1103,              0.49181,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,                    2\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01083, momentum=0.98, weight_decay=0.0005, warmup_epochs=3.46992, warmup_momentum=0.95, warmup_bias_lr=0.10308, box=0.05, cls=0.44687, cls_pw=1.31897, obj=1.05907, obj_pw=0.96439, iou_t=0.2, anchor_t=3.1057, fl_gamma=0.0, hsv_h=0.01684, hsv_s=0.61631, hsv_v=0.43596, degrees=0.0, translate=0.11678, scale=0.42016, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=4.85231\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=4.85231\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     62825  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46168809 parameters, 46168809 gradients, 108.3 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 213.83it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 15 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9331: 100% 1000/1000 [00:01<00:00, 817.11it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 13.53 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=15, img_size=416, metric_all=0.576/0.933-mean/best, past_thr=0.608-mean: 405,93, 275,166, 125,368, 379,124, 153,325, 397,149, 272,218, 350,196, 184,406, 396,199, 229,383, 283,320, 360,253, 405,252, 261,398\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.45G    0.09623     0.0294    0.02953         48        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.45G    0.07949    0.03151    0.02704         35        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.45G    0.06898    0.03433    0.02303         38        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.45G    0.06176    0.03687    0.02012         40        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.45G    0.05566    0.03785    0.01605         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.45G    0.05326    0.03717    0.01453         38        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.45G    0.05163    0.03729    0.01124         35        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.45G     0.0501    0.03599   0.009893         42        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.45G    0.04764    0.03643   0.009431         38        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.45G    0.04697    0.03381   0.007305         40        416: 100% 6/6 [00:03<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.44it/s]\n",
            "                   all         23         23      0.759      0.265      0.348      0.121\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m48 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.75873,              0.26471,              0.34771,               0.1211,             0.065606,              0.01584,             0.021596,              0.00991,              0.01083,                 0.98,               0.0005,               3.4699,                 0.95,              0.10308,                 0.05,              0.44687,                1.319,               1.0591,              0.96439,                  0.2,               3.1057,                    0,              0.01684,              0.61631,              0.43596,                    0,              0.11678,              0.42016,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               4.8523\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00962, lrf=0.01, momentum=0.94605, weight_decay=0.0005, warmup_epochs=2.81013, warmup_momentum=0.85677, warmup_bias_lr=0.09702, box=0.05035, cls=0.52273, cls_pw=1.08938, obj=0.92596, obj_pw=1.0, iou_t=0.2, anchor_t=4.0817, fl_gamma=0.0, hsv_h=0.01505, hsv_s=0.81996, hsv_v=0.40863, degrees=0.0, translate=0.09978, scale=0.49458, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.92617, mixup=0.0, copy_paste=0.0, anchors=2.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     25130  models.yolo.Detect                      [2, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46131114 parameters, 46131114 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 606/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00962) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.000546875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 210.88it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 6 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8915: 100% 1000/1000 [00:01<00:00, 791.34it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 5.95 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=6, img_size=416, metric_all=0.583/0.892-mean/best, past_thr=0.586-mean: 126,366, 383,134, 285,209, 190,392, 394,215, 245,377\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.46G     0.1008     0.0286    0.02853         30        416: 100% 6/6 [00:03<00:00,  1.55it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.46G    0.07858    0.03167    0.02514         40        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.46G    0.06301    0.03725    0.02052         38        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.46G    0.05914    0.03727    0.01697         39        416: 100% 6/6 [00:03<00:00,  1.61it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.46G    0.05505    0.03813     0.0135         44        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.46G    0.05353    0.03669    0.01089         33        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.46G    0.05372    0.03514   0.009616         34        416: 100% 6/6 [00:03<00:00,  1.57it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.46G    0.04919    0.03421    0.00883         42        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.46G    0.04621     0.0348   0.006807         39        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.46G    0.04726    0.03349   0.007836         30        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.46it/s]\n",
            "                   all         23         23      0.861      0.441      0.774      0.359\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m49 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.86077,              0.44118,              0.77361,              0.35863,             0.062426,             0.016124,              0.01678,              0.00962,                 0.01,              0.94605,               0.0005,               2.8101,              0.85677,              0.09702,              0.05035,              0.52273,               1.0894,              0.92596,                    1,                  0.2,               4.0817,                    0,              0.01505,              0.81996,              0.40863,                    0,              0.09978,              0.49458,                    0,                    0,                    0,                  0.5,              0.92617,                    0,                    0,                    2\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01028, momentum=0.95314, weight_decay=0.00045, warmup_epochs=3.06341, warmup_momentum=0.79646, warmup_bias_lr=0.10192, box=0.05, cls=0.47412, cls_pw=0.94592, obj=1.03977, obj_pw=0.97962, iou_t=0.2, anchor_t=4.0817, fl_gamma=0.0, hsv_h=0.01501, hsv_s=0.74664, hsv_v=0.40172, degrees=0.0, translate=0.1, scale=0.44216, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.87544\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.87544\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0004921875), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 212.40it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9117: 100% 1000/1000 [00:01<00:00, 824.83it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.912-mean/best, past_thr=0.590-mean: 122,369, 149,332, 385,130, 281,211, 351,189, 393,197, 196,400, 251,370, 385,244\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/evolve/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.48G     0.1163    0.01687   0.004926         49        416: 100% 6/6 [00:03<00:00,  1.56it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.48G     0.1079    0.01641   0.005819         34        416: 100% 6/6 [00:03<00:00,  1.65it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.48G     0.1035    0.01707   0.004841         38        416: 100% 6/6 [00:03<00:00,  1.62it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.48G    0.09753    0.01801   0.005316         41        416: 100% 6/6 [00:03<00:00,  1.63it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.48G    0.08822    0.01992   0.004056         43        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.48G    0.07792    0.02208   0.005249         38        416: 100% 6/6 [00:04<00:00,  1.45it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.48G    0.07051    0.02506   0.004633         35        416: 100% 6/6 [00:03<00:00,  1.51it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.48G    0.06735    0.02503   0.004288         42        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.48G    0.06354     0.0255   0.005033         40        416: 100% 6/6 [00:03<00:00,  1.58it/s]\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.48G     0.0646    0.02433   0.003782         41        416: 100% 6/6 [00:03<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.65it/s]\n",
            "                   all         23         23      0.682      0.799      0.745       0.33\n",
            "\n",
            "10 epochs completed in 0.011 hours.\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m50 generations finished, current result:\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m   metrics/precision,       metrics/recall,      metrics/mAP_0.5, metrics/mAP_0.5:0.95,         val/box_loss,         val/obj_loss,         val/cls_loss,                  lr0,                  lrf,             momentum,         weight_decay,        warmup_epochs,      warmup_momentum,       warmup_bias_lr,                  box,                  cls,               cls_pw,                  obj,               obj_pw,                iou_t,             anchor_t,             fl_gamma,                hsv_h,                hsv_s,                hsv_v,              degrees,            translate,                scale,                shear,          perspective,               flipud,               fliplr,               mosaic,                mixup,           copy_paste,              anchors\n",
            "\u001b[34m\u001b[1mevolve: \u001b[0m             0.68162,              0.79902,              0.74485,               0.3303,             0.082519,             0.011736,            0.0055367,                 0.01,              0.01028,              0.95314,              0.00045,               3.0634,              0.79646,              0.10192,                 0.05,              0.47412,              0.94592,               1.0398,              0.97962,                  0.2,               4.0817,                    0,              0.01501,              0.74664,              0.40172,                    0,                  0.1,              0.44216,                    0,                    0,                    0,                  0.5,                    1,                    0,                    0,               2.8754\n",
            "\n",
            "\n",
            "Best results from row 6 of runs/evolve/exp/evolve.csv:\n",
            "            lr0: 0.00991\n",
            "            lrf: 0.01\n",
            "       momentum: 0.946\n",
            "   weight_decay: 0.00049\n",
            "  warmup_epochs: 3.03\n",
            "warmup_momentum: 0.817\n",
            " warmup_bias_lr: 0.1\n",
            "            box: 0.05\n",
            "            cls: 0.491\n",
            "         cls_pw: 1.02\n",
            "            obj: 1\n",
            "         obj_pw: 1\n",
            "          iou_t: 0.2\n",
            "       anchor_t: 4.08\n",
            "       fl_gamma: 0\n",
            "          hsv_h: 0.0149\n",
            "          hsv_s: 0.719\n",
            "          hsv_v: 0.409\n",
            "        degrees: 0\n",
            "      translate: 0.1\n",
            "          scale: 0.494\n",
            "          shear: 0\n",
            "    perspective: 0\n",
            "         flipud: 0\n",
            "         fliplr: 0.5\n",
            "         mosaic: 1\n",
            "          mixup: 0\n",
            "     copy_paste: 0\n",
            "        anchors: 2.8\n",
            "Saved runs/evolve/exp/evolve.png\n",
            "Hyperparameter evolution finished 50 generations\n",
            "Results saved to \u001b[1mruns/evolve/exp\u001b[0m\n",
            "Usage example: $ python train.py --hyp runs/evolve/exp/hyp_evolve.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --epochs 10 --batch 35 --data /content/drive/MyDrive/fish/fish_project/datafile.yaml --cfg /content/yolov5/models/yolov5l.yaml --weights /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt --hyp  runs/evolve/exp/hyp_evolve.yaml --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3aTcQtmtYTh",
        "outputId": "ba66527d-50a2-49de-f898-22f12b7f3474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt, cfg=/content/yolov5/models/yolov5l.yaml, data=/content/drive/MyDrive/fish/fish_project/datafile.yaml, hyp=runs/evolve/exp/hyp_evolve.yaml, epochs=10, batch_size=35, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 2 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v7.0-10-g10c025d Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00991, lrf=0.01, momentum=0.94605, weight_decay=0.00049, warmup_epochs=3.0328, warmup_momentum=0.81718, warmup_bias_lr=0.1, box=0.05, cls=0.49134, cls_pw=1.0175, obj=1.0041, obj_pw=1.0, iou_t=0.2, anchor_t=4.0817, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.71879, hsv_v=0.40863, degrees=0.0, translate=0.1, scale=0.49412, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, anchors=2.8018\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "Overriding model.yaml anchors with anchors=2.8018\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "Transferred 612/613 items from /content/drive/MyDrive/fish/fish_project/runs/train/exp15/weights/best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00991) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005359375), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fish_detection.cache... 192 images, 0 backgrounds, 0 corrupt: 100% 192/192 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 192/192 [00:00<00:00, 225.68it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/fish/fish_project/fishval.cache... 23 images, 0 backgrounds, 0 corrupt: 100% 23/23 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 23/23 [00:00<00:00, 82.87it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m0.00 anchors/target, 0.000 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 192 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9124: 100% 1000/1000 [00:00<00:00, 1351.25it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.24: 1.0000 best possible recall, 8.94 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.586/0.912-mean/best, past_thr=0.589-mean: 123,372, 377,127, 151,334, 282,208, 361,186, 191,393, 396,203, 242,375, 386,248\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      9.51G     0.1162    0.01653   0.005313         49        416: 100% 6/6 [00:07<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.18it/s]\n",
            "                   all         23         23      0.346      0.168      0.133     0.0715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      9.51G     0.1074    0.01596   0.006214         36        416: 100% 6/6 [00:03<00:00,  1.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.04it/s]\n",
            "                   all         23         23       0.43      0.314      0.315      0.076\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      9.51G     0.1001    0.01736   0.005115         39        416: 100% 6/6 [00:03<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.42it/s]\n",
            "                   all         23         23      0.369      0.273      0.227      0.044\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      9.51G    0.09164    0.01927   0.005715         41        416: 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.00it/s]\n",
            "                   all         23         23      0.161      0.284      0.133     0.0407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      9.51G    0.08371    0.02075   0.004411         45        416: 100% 6/6 [00:03<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.44it/s]\n",
            "                   all         23         23      0.447      0.515      0.486      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      9.51G    0.07584    0.02221   0.005462         38        416: 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.33it/s]\n",
            "                   all         23         23      0.596      0.685      0.655      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      9.51G    0.07007    0.02444   0.004798         34        416: 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.45it/s]\n",
            "                   all         23         23      0.796      0.792      0.731      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      9.51G    0.06755    0.02479   0.004409         43        416: 100% 6/6 [00:03<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.47it/s]\n",
            "                   all         23         23      0.836      0.549      0.561      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      9.51G    0.06356    0.02522   0.005429         40        416: 100% 6/6 [00:03<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.34it/s]\n",
            "                   all         23         23      0.753      0.775      0.874      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      9.51G    0.06403    0.02422   0.003952         41        416: 100% 6/6 [00:03<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.51it/s]\n",
            "                   all         23         23      0.846      0.805      0.854      0.426\n",
            "\n",
            "10 epochs completed in 0.018 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 92.8MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 92.8MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5l summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.13it/s]\n",
            "                   all         23         23      0.846      0.804      0.854      0.427\n",
            "                 fresh         23         17      0.693      0.824      0.766      0.316\n",
            "                 stale         23          6          1      0.785      0.942      0.538\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/yolov5/runs -r /content/drive/MyDrive/fish/fish_project"
      ],
      "metadata": {
        "id": "lP2ENZgGAhF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "img=cv.imread('/content/rohu_test.jpg')\n",
        "res=cv.resize(img,(416,416),interpolation=cv.INTER_AREA)\n",
        "cv.imwrite('/content/rohu_test.jpg',res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJkHtU1u-jwD",
        "outputId": "8601e580-c7a5-461b-a03a-3a1a11a0a69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python detect.py --source /content/rohu_test.jpg  --img 416 --weights /content/yolov5/runs/train/exp2/weights/best.pt  --line-thickness 1 --hide-conf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8OYXvKg3H2u",
        "outputId": "6d2813e0-1832-475b-a418-ca1059b1a639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp2/weights/best.pt'], source=/content/rohu_test.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-10-g10c025d Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5l summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
            "image 1/1 /content/rohu_test.jpg: 416x416 1 fresh, 30.4ms\n",
            "Speed: 0.4ms pre-process, 30.4ms inference, 1.4ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp8\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEfCODav_YBz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}